# ğŸ­ SKEMA Hackathon - SystÃ¨me de DÃ©tection de DÃ©fauts Industriels

Un pipeline machine learning complet de bout en bout pour la dÃ©tection automatisÃ©e de dÃ©fauts industriels utilisant l'apprentissage par ensemble et la recherche d'images par le contenu (CBIR). Ce projet combine des techniques d'apprentissage profond, de machine learning classique et de vision par ordinateur pour classifier les composants industriels comme dÃ©fectueux ou non-dÃ©fectueux avec une grande confiance.

---
ğŸ‘‰ **DÃ©mo en ligne :** [Application Streamlit](https://skema-hackathon.streamlit.app)

---

## ğŸ“‹ Table des matiÃ¨res

- [AperÃ§u](#aperÃ§u)
- [FonctionnalitÃ©s](#fonctionnalitÃ©s)
- [Architecture](#architecture)
- [Technologies](#technologies)
- [Installation](#installation)
- [Utilisation](#utilisation)
- [Structure du projet](#structure-du-projet)
- [ModÃ¨les](#modÃ¨les)
- [DonnÃ©es](#donnÃ©es)
- [Contribuer](#contribuer)

## ğŸ¯ AperÃ§u

Ce systÃ¨me offre :
- **PrÃ©diction par ensemble** : Combine plusieurs modÃ¨les de deep learning et ML classiques pour une classification robuste des dÃ©fauts
- **Interface web interactive** : Application basÃ©e sur Streamlit pour un tÃ©lÃ©versement et une analyse faciles des images
- **Recherche d'images par le contenu** : Trouve des images similaires dans la base de donnÃ©es pour aider Ã  la prise de dÃ©cision
- **PrÃ©dictions haute confiance** : Le vote majoritaire entre plus de 5 modÃ¨les garantit des rÃ©sultats fiables
- **ExplicabilitÃ©** : Affiche les votes individuels des modÃ¨les et les scores de confiance

### Qu'est-ce qui rend ce projet unique ?

- **Gabarit prÃªt pour hackathon** : Structure claire et bien organisÃ©e parfaite pour le dÃ©veloppement rapide
- **Approche hybride** : Combine des CNN personnalisÃ©s avec des extracteurs prÃ©-entraÃ®nÃ©s et du ML classique
- **PrÃ©dictions robustes** : Le vote par ensemble rÃ©duit les erreurs des modÃ¨les individuels
- **PrÃªt pour la production** : Inclut un mode dÃ©mo et des replis gracieux

## âœ¨ FonctionnalitÃ©s

### ğŸ” Pipeline de classification
- **CNN de base personnalisÃ©** : RÃ©seau de neurones convolutionnel conÃ§u spÃ©cifiquement
- **Extracteurs de caractÃ©ristiques prÃ©-entraÃ®nÃ©s** : ResNet50, VGG16, DenseNet121
- **Classificateurs ML classiques** : SVM, XGBoost, Random Forest, LightGBM
- **Vote par ensemble** : Vote majoritaire entre plusieurs prÃ©dictions de modÃ¨les
- **Score de confiance** : Confiance en pourcentage avec dÃ©tail des votes

### ğŸ–¼ï¸ Recherche d'images par le contenu (CBIR)
- **Multiples extracteurs de caractÃ©ristiques** : Support pour ResNet50, VGG16, DenseNet121
- **MÃ©triques de distance** : Euclidienne, Cosinus, Manhattan, Chebyshev, et plus
- **K plus proches voisins** : Trouve des images visuellement similaires dans la base de donnÃ©es
- **SimilaritÃ© visuelle** : Affiche les images similaires avec leurs scores de distance

### ğŸ“Š Interface web interactive
- TÃ©lÃ©versement d'images par glisser-dÃ©poser
- PrÃ©diction en temps rÃ©el avec retour visuel
- Visualisation des votes des modÃ¨les avec graphiques Plotly
- Exploration d'images similaires
- Design responsive optimisÃ© pour l'usage industriel

## ğŸ—ï¸ Architecture

### Vue d'ensemble du systÃ¨me

```
IMAGE EN ENTRÃ‰E (224Ã—224)
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         EXTRACTION DE CARACTÃ‰RISTIQUES    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  â”œâ”€â†’ CNN de base personnalisÃ©            â”‚
â”‚  â”œâ”€â†’ ResNet50 â†’ Vecteur de features      â”‚
â”‚  â”œâ”€â†’ VGG16 â†’ Vecteur de features         â”‚
â”‚  â””â”€â†’ DenseNet121 â†’ Vecteur de features   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         COUCHE DE CLASSIFICATION          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  â”œâ”€â†’ PrÃ©diction directe CNN              â”‚
â”‚  â”œâ”€â†’ Classificateurs SVM (par extractor) â”‚
â”‚  â”œâ”€â†’ Classificateurs XGBoost             â”‚
â”‚  â””â”€â†’ Classificateurs Random Forest       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         AGRÃ‰GATION PAR ENSEMBLE           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Vote majoritaire (5+ prÃ©dictions)       â”‚
â”‚  Confiance = Pourcentage d'accord         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“
PRÃ‰DICTION FINALE + CONFIANCE + EXPLICATION
```

### SystÃ¨me Ã  double workflow

#### 1. **Workflow de classification**
```python
Image â†’ Extraction features â†’ Classificateurs multiples â†’ Vote â†’ RÃ©sultat
```
- TÃ©lÃ©verser l'image du composant industriel
- Extraire les caractÃ©ristiques avec les backbones CNN
- Appliquer plusieurs classificateurs
- AgrÃ©ger les prÃ©dictions via vote majoritaire
- Afficher les rÃ©sultats avec scores de confiance

#### 2. **Workflow CBIR**
```python
Image requÃªte â†’ Extraction features â†’ Base signatures â†’ Recherche K-NN â†’ Images similaires
```
- Extraire les caractÃ©ristiques de l'image requÃªte
- Comparer avec la base de signatures prÃ©-calculÃ©es
- RÃ©cupÃ©rer les K images les plus similaires
- Afficher avec mÃ©triques de distance

## ğŸ› ï¸ Technologies

| CatÃ©gorie | Technologie | Version |
|----------|-----------|---------|
| **Deep Learning** | PyTorch | 2.10 |
| **Deep Learning** | torchvision | 0.25 |
| **Framework Web** | Streamlit | 1.54 |
| **Framework ML** | scikit-learn | DerniÃ¨re |
| **Boosting** | XGBoost | 3.1 |
| **Boosting** | LightGBM | DerniÃ¨re |
| **Traitement donnÃ©es** | NumPy | DerniÃ¨re |
| **Traitement donnÃ©es** | Pandas | DerniÃ¨re |
| **Vision par ordinateur** | OpenCV | DerniÃ¨re |
| **Traitement d'images** | Pillow | DerniÃ¨re |
| **Visualisation** | Plotly | 6.5 |

## ğŸ“¦ Installation

### PrÃ©requis
- Python 3.8 ou supÃ©rieur
- Gestionnaire de paquets pip
- (Optionnel) GPU compatible CUDA pour l'entraÃ®nement

### Configuration

1. **Cloner le dÃ©pÃ´t**
```bash
git clone <url-du-dÃ©pÃ´t>
cd skema-hackathon
```

2. **CrÃ©er un environnement virtuel** (recommandÃ©)
```bash
python -m venv venv
source venv/bin/activate  # Sur Windows : venv\Scripts\activate
```

3. **Installer les dÃ©pendances**
```bash
pip install -r requirements.txt
```

### DÃ©pendances
Le fichier `requirements.txt` inclut tous les paquets nÃ©cessaires :
```
streamlit==1.54.0
torch==2.10.0
torchvision==0.25.0
numpy
pandas
pillow
opencv-python
scikit-learn
xgboost==3.1.0
lightgbm
plotly==6.5.0
```

## ğŸš€ Utilisation

### Lancer l'application web

1. **DÃ©marrer le serveur Streamlit**
```bash
streamlit run streamlit_app.py
```

2. **AccÃ©der Ã  l'application**
- Ouvrir votre navigateur sur `http://localhost:8501`
- L'application fonctionnera en mode dÃ©mo si les modÃ¨les ne sont pas disponibles

3. **Utiliser l'interface**
- Activer le **Mode DÃ©mo** dans la barre latÃ©rale si aucun modÃ¨le entraÃ®nÃ© n'existe
- TÃ©lÃ©verser une image (JPG, PNG)
- Cliquer sur **"Analyze Image"** pour obtenir :
  - PrÃ©diction finale (DÃ©fectueux / OK)
  - Score de confiance global
  - Votes des modÃ¨les individuels
  - Visualisation jauge de confiance
  - Graphique de rÃ©partition des votes

### EntraÃ®ner les modÃ¨les

ExÃ©cuter le script d'entraÃ®nement pour crÃ©er tous les modÃ¨les :
```bash
python J2/train_and_save_models_jour2.py
```

Cela va :
- EntraÃ®ner le CNN de base Ã  partir de zÃ©ro
- Extraire les caractÃ©ristiques avec les modÃ¨les prÃ©-entraÃ®nÃ©s (ResNet50, VGG16, DenseNet121)
- EntraÃ®ner les classificateurs superficiels (SVM, XGBoost, Random Forest)
- Sauvegarder tous les modÃ¨les dans le dossier `models/`
- Sauvegarder les scalers de caractÃ©ristiques pour la normalisation

### CrÃ©er les signatures CBIR

GÃ©nÃ©rer les bases de donnÃ©es de signatures pour la recherche de similaritÃ© :
```bash
python misc/create_signatures.py
```

Cela crÃ©e des bases de signatures dans `signatures/` pour :
- CaractÃ©ristiques ResNet50
- CaractÃ©ristiques VGG16
- CaractÃ©ristiques DenseNet121

### Utiliser les notebooks Jupyter

Le projet inclut des notebooks pour l'exploration et l'expÃ©rimentation :

1. **Notebooks Jour 1** : `01.1hackathon_notebook_template_jour1.ipynb`
   - Exploration des donnÃ©es
   - PrÃ©traitement de base
   - ExpÃ©riences de modÃ¨les initiaux

2. **Notebooks Jour 2** : SituÃ©s dans `J2/`
   - EntraÃ®nement de modÃ¨les avancÃ©s
   - Extraction de caractÃ©ristiques
   - Ã‰valuation des modÃ¨les

3. **Ouvrir avec Jupyter**
```bash
jupyter notebook
```

## ğŸ“ Structure du projet

```
skema-hackathon/
â”œâ”€â”€ streamlit_app.py                       # Application Streamlit principale
â”œâ”€â”€ requirements.txt                       # DÃ©pendances Python
â”œâ”€â”€ README.md                              # Ce fichier
â”‚
â”œâ”€â”€ data/                                  # RÃ©pertoire des donnÃ©es
â”‚   â”œâ”€â”€ train/
â”‚   â”‚   â”œâ”€â”€ defective/                     # EntraÃ®nement : composants dÃ©fectueux
â”‚   â”‚   â””â”€â”€ non_defective/                 # EntraÃ®nement : composants normaux
â”‚   â””â”€â”€ test/
â”‚       â”œâ”€â”€ defective/                     # Test : composants dÃ©fectueux
â”‚       â””â”€â”€ non_defective/                 # Test : composants normaux
â”‚
â”œâ”€â”€ models/                                # Fichiers des modÃ¨les entraÃ®nÃ©s
â”‚   â”œâ”€â”€ baseline_cnn.pth                   # Poids PyTorch du CNN
â”‚   â”œâ”€â”€ resnet50_svm.pkl                   # Classificateur ResNet50 + SVM
â”‚   â”œâ”€â”€ resnet50_xgboost.pkl               # ResNet50 + XGBoost
â”‚   â”œâ”€â”€ resnet50_rf.pkl                    # ResNet50 + Random Forest
â”‚   â”œâ”€â”€ resnet50_scaler.pkl                # Scaler de features pour ResNet50
â”‚   â”œâ”€â”€ vgg16_*.pkl                        # ModÃ¨les et scaler VGG16
â”‚   â””â”€â”€ densenet121_*.pkl                  # ModÃ¨les et scaler DenseNet121
â”‚
â”œâ”€â”€ signatures/                            # Bases de donnÃ©es signatures CBIR
â”‚   â”œâ”€â”€ signatures_resnet50.pkl            # Signatures features ResNet50
â”‚   â”œâ”€â”€ signatures_vgg16.pkl               # Signatures features VGG16
â”‚   â””â”€â”€ signatures_densenet121.pkl         # Signatures features DenseNet121
â”‚
â”œâ”€â”€ J2/                                    # MatÃ©riaux de dÃ©veloppement Jour 2
â”‚   â”œâ”€â”€ train_and_save_models_jour2.py     # Script d'entraÃ®nement des modÃ¨les
â”‚   â””â”€â”€ [notebooks et expÃ©riences]
â”‚
â”œâ”€â”€ J3/                                    # MatÃ©riaux Jour 3
â”‚
â”œâ”€â”€ misc/                                  # Utilitaires et alternatives
â”‚   â”œâ”€â”€ create_signatures.py               # Constructeur de base CBIR
â”‚   â”œâ”€â”€ streamlit_app_complete.py          # Version complÃ¨te de l'app
â”‚   â””â”€â”€ utils.py                           # Fonctions utilitaires
â”‚
â””â”€â”€ 01.1hackathon_notebook_template_jour1.ipynb  # Notebook Jour 1
```

## ğŸ¤– ModÃ¨les

### 1. Architecture CNN de base

**BaselineCNN** - RÃ©seau de neurones convolutionnel personnalisÃ© :

```python
EntrÃ©e (224Ã—224Ã—3)
    â†“
Conv2D(32) â†’ ReLU â†’ MaxPool
    â†“
Conv2D(64) â†’ ReLU â†’ MaxPool
    â†“
Conv2D(128) â†’ ReLU â†’ MaxPool
    â†“
Flatten â†’ FC(512) â†’ Dropout â†’ FC(2)
    â†“
Sortie (2 classes)
```

- **Objectif** : Classification binaire directe
- **Classes** : 0 = Non-dÃ©fectueux, 1 = DÃ©fectueux
- **Fichier** : `models/baseline_cnn.pth`

### 2. Extracteurs de caractÃ©ristiques par transfert learning

Backbones CNN prÃ©-entraÃ®nÃ©s (poids ImageNet) :

| ModÃ¨le | Dimensions sortie | Points forts |
|-------|------------|-----------|
| **ResNet50** | 2048 | Connexions rÃ©siduelles profondes, excellent pour les motifs complexes |
| **VGG16** | 4096 | Architecture simple, bon pour les caractÃ©ristiques de texture |
| **DenseNet121** | 1024 | Connexions denses, rÃ©utilisation efficace des features |

### 3. Classificateurs classiques

AppliquÃ©s aux caractÃ©ristiques extraites :

- **Machine Ã  vecteurs de support (SVM)**
  - Noyaux linÃ©aires et RBF
  - Excellent pour les espaces de caractÃ©ristiques haute dimension
  
- **XGBoost**
  - Arbres de dÃ©cision Ã  gradient boosting
  - GÃ¨re bien les relations non-linÃ©aires
  
- **Random Forest**
  - Ensemble d'arbres de dÃ©cision
  - Robuste au surapprentissage
  
- **LightGBM** (optionnel)
  - Gradient boosting rapide
  - Efficace en mÃ©moire

### Convention de nommage des modÃ¨les

```
{extracteur}_{classificateur}.pkl
```

**Exemples :**
- `resnet50_svm.pkl` - SVM entraÃ®nÃ© sur features ResNet50
- `vgg16_xgboost.pkl` - XGBoost entraÃ®nÃ© sur features VGG16
- `densenet121_rf.pkl` - Random Forest sur features DenseNet121

### Scalers de caractÃ©ristiques

Chaque extracteur de caractÃ©ristiques a un StandardScaler associÃ© :
- `resnet50_scaler.pkl`
- `vgg16_scaler.pkl`
- `densenet121_scaler.pkl`

Les scalers normalisent les caractÃ©ristiques Ã  moyenne nulle et variance unitaire avant classification.

### Vote par ensemble

Le systÃ¨me combine tous les modÃ¨les disponibles :
1. Collecter les prÃ©dictions de tous les modÃ¨les
2. Compter les votes pour chaque classe
3. SÃ©lectionner la classe majoritaire
4. Calculer confiance = (votes majoritaires / votes totaux) Ã— 100%

**Exemple :**
- 5 modÃ¨les votent : [DÃ©fectueux, DÃ©fectueux, OK, DÃ©fectueux, DÃ©fectueux]
- RÃ©sultat : DÃ©fectueux avec 80% de confiance

## ğŸ“Š DonnÃ©es

### Structure du jeu de donnÃ©es

```
data/
â”œâ”€â”€ train/
â”‚   â”œâ”€â”€ defective/          # Composants dÃ©fectueux
â”‚   â”‚   â”œâ”€â”€ defect_001.jpg
â”‚   â”‚   â”œâ”€â”€ defect_002.jpg
â”‚   â”‚   â””â”€â”€ ...
â”‚   â””â”€â”€ non_defective/      # Composants normaux
â”‚       â”œâ”€â”€ normal_001.jpg
â”‚       â”œâ”€â”€ normal_002.jpg
â”‚       â””â”€â”€ ...
â””â”€â”€ test/
    â”œâ”€â”€ defective/
    â””â”€â”€ non_defective/
```

### Exigences pour les images

- **Formats** : JPG, PNG, BMP, GIF
- **Taille d'entrÃ©e** : Redimensionnement automatique Ã  224Ã—224 pixels
- **Canaux** : RGB (3 canaux)
- **Contenu** : Composants industriels, piÃ¨ces ou assemblages
- **RecommandÃ©** : Images claires, bien Ã©clairÃ©es avec arriÃ¨re-plans cohÃ©rents

### Mode dÃ©mo

L'application inclut un **mode dÃ©mo** qui fonctionne sans modÃ¨les entraÃ®nÃ©s :
- Simule des prÃ©dictions avec confiance alÃ©atoire
- Utile pour tester l'UI/UX
- Activer dans la barre latÃ©rale : bouton "Demo Mode"

## ğŸ”§ Configuration

### Personnaliser l'ensemble de modÃ¨les

Modifier les extracteurs et classificateurs dans les scripts d'entraÃ®nement :

```python
# Dans train_and_save_models_jour2.py
extractors = ['resnet50', 'vgg16', 'densenet121']
classifiers = ['svm', 'xgboost', 'rf']
```

### ParamÃ¨tres CBIR

Ajuster dans la barre latÃ©rale de l'app Streamlit :
- **Extracteur de caractÃ©ristiques** : ResNet50, VGG16, DenseNet121
- **MÃ©trique de distance** : 
  - Euclidienne (L2)
  - SimilaritÃ© Cosinus
  - Manhattan (L1)
  - Chebyshev
- **K Voisins** : 1-20 images similaires

### ParamÃ¨tres d'entraÃ®nement

ParamÃ¨tres courants dans les notebooks d'entraÃ®nement :
```python
BATCH_SIZE = 32
LEARNING_RATE = 0.001
EPOCHS = 20
IMG_SIZE = 224
```

## ğŸ“ˆ MÃ©triques de performance

L'approche par ensemble offre :

- **Robustesse** : RÃ©duit l'impact des erreurs de modÃ¨les individuels
- **Estimation de confiance** : La distribution des votes indique la certitude
- **ExplicabilitÃ©** : Voir quels modÃ¨les sont d'accord/en dÃ©saccord
- **FlexibilitÃ©** : Fonctionne mÃªme avec des ensembles de modÃ¨les partiels
- **PrÃ©cision** : Typiquement supÃ©rieure aux modÃ¨les individuels

**Surveillance :**
- PrÃ©cision globale
- PrÃ©cision/rappel par classe
- Matrices de confusion
- Contributions des modÃ¨les individuels

## ğŸ¤ Contribuer

Ce projet a Ã©tÃ© dÃ©veloppÃ© pour le Hackathon SKEMA. Les contributions et amÃ©liorations sont les bienvenues !

### Comment contribuer

1. Forker le dÃ©pÃ´t
2. CrÃ©er une branche de fonctionnalitÃ©
   ```bash
   git checkout -b feature/amelioration-incroyable
   ```
3. Commiter vos modifications
   ```bash
   git commit -am 'Ajout amÃ©lioration incroyable'
   ```
4. Pousser vers la branche
   ```bash
   git push origin feature/amelioration-incroyable
   ```
5. CrÃ©er une Pull Request

### Pistes d'amÃ©lioration

- [ ] Ajouter plus d'extracteurs prÃ©-entraÃ®nÃ©s (EfficientNet, Vision Transformer)
- [ ] ImplÃ©menter le vote pondÃ©rÃ© (au lieu du vote majoritaire simple)
- [ ] Ajouter la calibration des modÃ¨les pour de meilleurs scores de confiance
- [ ] Support de la classification multi-classes de dÃ©fauts
- [ ] ImplÃ©menter des pipelines d'augmentation de donnÃ©es
- [ ] Ajouter l'apprentissage actif pour un Ã©tiquetage efficace
- [ ] CrÃ©er un endpoint API REST
- [ ] Ajouter la surveillance des performances des modÃ¨les
- [ ] ImplÃ©menter un framework de tests A/B

## ğŸ“ Licence

Ce projet a Ã©tÃ© crÃ©Ã© pour le Hackathon SKEMA. Veuillez consulter les organisateurs pour les informations de licence.

## ğŸ™ Remerciements

- **SKEMA Business School** pour l'organisation du hackathon
- **L'Ã©quipe PyTorch** pour l'excellent framework de deep learning
- **Streamlit** pour le framework web intuitif
- **torchvision** pour les modÃ¨les prÃ©-entraÃ®nÃ©s
- **La communautÃ© ML open-source** pour les outils prÃ©cieux

## ğŸ“§ Support

Pour des questions, problÃ¨mes ou suggestions :
- Ouvrir une issue sur GitHub
- Contacter les mainteneurs du projet
- Consulter la [dÃ©mo en ligne](https://skema-hackathon.streamlit.app)

---

**DÃ©veloppÃ© avec â¤ï¸ pour le Hackathon SKEMA**

**Bonne dÃ©tection ! ğŸ”ğŸ­**
