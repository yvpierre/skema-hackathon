{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üè≠ Hackathon - D√©tection de D√©fauts Industriels avec IA\n",
    "\n",
    "## üìã Objectif\n",
    "Construire un syst√®me complet de d√©tection de d√©fauts sur des pi√®ces industrielles en utilisant:\n",
    "- **Machine Learning / Deep Learning** pour la classification\n",
    "- **CBIR** (Content-Based Image Retrieval) pour la recherche par similarit√©\n",
    "- **VLM** (Vision Language Model) pour la description automatique\n",
    "\n",
    "---\n",
    "\n",
    "## üóìÔ∏è Programme\n",
    "| Jour | Th√®me | Livrables |\n",
    "|------|-------|----------|\n",
    "| 1 | Fondamentaux | Pipeline ML/DL baseline |\n",
    "| 2 | Optimisation | Hyperparam√®tres + Interface Streamlit |\n",
    "| 3 | CBIR | Syst√®me de recherche par similarit√© |\n",
    "| 4 | VLM | Description automatique + Int√©gration finale |\n",
    "\n",
    "---\n",
    "\n",
    "## ‚ö†Ô∏è R√®gles du Hackathon\n",
    "- ‚úÖ Utiliser les ressources fournies\n",
    "- ‚úÖ Collaborer en √©quipe\n",
    "- ‚úÖ Documenter votre code\n",
    "- ‚ùå Ne pas copier le code final des autres √©quipes\n",
    "\n",
    "**Bonne chance! üöÄ**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# üì¶ SECTION 0: Configuration de l'Environnement\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Installation des d√©pendances (d√©commenter si n√©cessaire)\n",
    "# !pip install torch torchvision scikit-learn xgboost lightgbm\n",
    "# !pip install matplotlib seaborn pillow\n",
    "# !pip install transformers accelerate  # Pour VLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports de base\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Deep Learning\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import models, transforms\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "# Machine Learning\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score,\n",
    "    confusion_matrix, classification_report\n",
    ")\n",
    "\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {DEVICE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration des chemins - √Ä MODIFIER selon votre structure\n",
    "DATA_DIR = Path(\"./data\")\n",
    "TRAIN_DIR = DATA_DIR / \"train\"\n",
    "TEST_DIR = DATA_DIR / \"test\"\n",
    "MODELS_DIR = Path(\"./models\")\n",
    "MODELS_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "# Classes\n",
    "CLASSES = ['non_defective', 'defective']\n",
    "NUM_CLASSES = 2\n",
    "\n",
    "# Param√®tres images\n",
    "IMG_SIZE = 224\n",
    "BATCH_SIZE = 32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# üìä SECTION 1: Exploration des Donn√©es (EDA)\n",
    "---\n",
    "\n",
    "## üí° Objectif\n",
    "Comprendre la distribution de vos donn√©es avant de construire le mod√®le.\n",
    "\n",
    "## üéØ TODO pour votre √©quipe:\n",
    "1. Compter le nombre d'images par classe\n",
    "2. Visualiser quelques exemples\n",
    "3. V√©rifier la taille et qualit√© des images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Compl√©ter cette fonction pour compter les images\n",
    "def count_images(directory):\n",
    "    \"\"\"\n",
    "    Compte le nombre d'images par classe dans un r√©pertoire.\n",
    "    \n",
    "    Args:\n",
    "        directory: Chemin vers le r√©pertoire (train ou test)\n",
    "    \n",
    "    Returns:\n",
    "        dict: {'defective': count, 'non_defective': count}\n",
    "    \"\"\"\n",
    "    counts = {}\n",
    "    \n",
    "    # VOTRE CODE ICI\n",
    "    # Hint: Parcourir les sous-dossiers et compter les fichiers .jpg, .png\n",
    "    \n",
    "    return counts\n",
    "\n",
    "# Test\n",
    "print(\"Distribution Train:\", count_images(TRAIN_DIR))\n",
    "print(\"Distribution Test:\", count_images(TEST_DIR))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Visualiser des exemples d'images\n",
    "def visualize_samples(directory, n_samples=4):\n",
    "    \"\"\"\n",
    "    Affiche des exemples d'images pour chaque classe.\n",
    "    \n",
    "    Hint: Utilisez matplotlib avec subplot\n",
    "    \"\"\"\n",
    "    fig, axes = plt.subplots(2, n_samples, figsize=(15, 6))\n",
    "    \n",
    "    for i, class_name in enumerate(CLASSES):\n",
    "        class_dir = directory / class_name\n",
    "        # VOTRE CODE ICI\n",
    "        # 1. Lister les fichiers dans class_dir\n",
    "        # 2. Charger n_samples images\n",
    "        # 3. Afficher avec axes[i, j].imshow()\n",
    "        pass\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "visualize_samples(TRAIN_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ‚ùì Questions de r√©flexion:\n",
    "1. Vos classes sont-elles √©quilibr√©es?\n",
    "2. Quelles caract√©ristiques visuelles distinguent les d√©fauts?\n",
    "3. Y a-t-il des variations de luminosit√©/angle dans les images?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# üñºÔ∏è SECTION 2: Pr√©traitement des Images\n",
    "---\n",
    "\n",
    "## üí° Concepts cl√©s\n",
    "\n",
    "### Normalisation ImageNet\n",
    "Les mod√®les pr√©-entra√Æn√©s (VGG, ResNet) attendent des images normalis√©es:\n",
    "- **Mean**: [0.485, 0.456, 0.406]\n",
    "- **Std**: [0.229, 0.224, 0.225]\n",
    "\n",
    "### Data Augmentation\n",
    "Techniques pour augmenter artificiellement le dataset:\n",
    "- Rotation, flip horizontal\n",
    "- Variation de luminosit√©\n",
    "- Crop al√©atoire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transforms pour l'entra√Ænement (avec augmentation)\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.RandomRotation(degrees=15),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(\n",
    "        mean=[0.485, 0.456, 0.406],\n",
    "        std=[0.229, 0.224, 0.225]\n",
    "    )\n",
    "])\n",
    "\n",
    "# Transforms pour test/inf√©rence (PAS d'augmentation)\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(\n",
    "        mean=[0.485, 0.456, 0.406],\n",
    "        std=[0.229, 0.224, 0.225]\n",
    "    )\n",
    "])\n",
    "\n",
    "print(\"‚úÖ Transforms d√©finis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Cr√©er un Dataset personnalis√©\n",
    "class DefectDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Dataset pour les images de d√©fauts.\n",
    "    \n",
    "    Structure attendue:\n",
    "    data_dir/\n",
    "    ‚îú‚îÄ‚îÄ defective/\n",
    "    ‚îÇ   ‚îî‚îÄ‚îÄ *.jpg, *.png\n",
    "    ‚îî‚îÄ‚îÄ non_defective/\n",
    "        ‚îî‚îÄ‚îÄ *.jpg, *.png\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, data_dir, transform=None):\n",
    "        self.data_dir = Path(data_dir)\n",
    "        self.transform = transform\n",
    "        self.samples = []  # Liste de (chemin_image, label)\n",
    "        \n",
    "        # TODO: Remplir self.samples\n",
    "        # Hint: Parcourir chaque classe, chaque image\n",
    "        # Label: 0 = non_defective, 1 = defective\n",
    "        \n",
    "        # VOTRE CODE ICI\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_path, label = self.samples[idx]\n",
    "        \n",
    "        # TODO: Charger et transformer l'image\n",
    "        # Hint: Image.open(), self.transform()\n",
    "        \n",
    "        # VOTRE CODE ICI\n",
    "        image = None  # √Ä remplacer\n",
    "        \n",
    "        return image, label\n",
    "\n",
    "# Test\n",
    "# train_dataset = DefectDataset(TRAIN_DIR, transform=train_transform)\n",
    "# print(f\"Nombre d'images: {len(train_dataset)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# üß† SECTION 3: Extraction de Caract√©ristiques avec CNN\n",
    "---\n",
    "\n",
    "## üí° Concept: Transfer Learning\n",
    "\n",
    "Utiliser un CNN pr√©-entra√Æn√© sur ImageNet comme **extracteur de features**:\n",
    "1. Charger le mod√®le (VGG16, ResNet50, etc.)\n",
    "2. Retirer la derni√®re couche (classification)\n",
    "3. Passer l'image ‚Üí Obtenir un vecteur de features\n",
    "\n",
    "### Dimensions des features par mod√®le:\n",
    "| Mod√®le | Dimension |\n",
    "|--------|----------|\n",
    "| VGG16 | 4096 |\n",
    "| ResNet50 | 2048 |\n",
    "| DenseNet121 | 1024 |\n",
    "| MobileNetV2 | 1280 |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exemple: Feature Extractor avec ResNet50\n",
    "class FeatureExtractor(nn.Module):\n",
    "    \"\"\"\n",
    "    Extrait les features d'une image en utilisant un CNN pr√©-entra√Æn√©.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, model_name='resnet50'):\n",
    "        super().__init__()\n",
    "        \n",
    "        if model_name == 'resnet50':\n",
    "            base_model = models.resnet50(pretrained=True)\n",
    "            # Retirer la derni√®re couche FC\n",
    "            self.features = nn.Sequential(*list(base_model.children())[:-1])\n",
    "            self.output_dim = 2048\n",
    "            \n",
    "        elif model_name == 'vgg16':\n",
    "            base_model = models.vgg16(pretrained=True)\n",
    "            self.features = base_model.features\n",
    "            self.avgpool = base_model.avgpool\n",
    "            # Utiliser seulement les features, pas le classifier\n",
    "            self.output_dim = 512 * 7 * 7  # 25088\n",
    "            \n",
    "        # TODO: Ajouter d'autres mod√®les (DenseNet, MobileNet)\n",
    "        \n",
    "        # Geler les poids (pas de fine-tuning)\n",
    "        for param in self.parameters():\n",
    "            param.requires_grad = False\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = x.view(x.size(0), -1)  # Flatten\n",
    "        return x\n",
    "\n",
    "# Test\n",
    "extractor = FeatureExtractor('resnet50').to(DEVICE)\n",
    "extractor.eval()\n",
    "\n",
    "# Test avec une image al√©atoire\n",
    "dummy_img = torch.randn(1, 3, 224, 224).to(DEVICE)\n",
    "features = extractor(dummy_img)\n",
    "print(f\"Shape des features: {features.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Extraire les features de tout le dataset\n",
    "def extract_all_features(data_dir, extractor, transform):\n",
    "    \"\"\"\n",
    "    Extrait les features de toutes les images d'un r√©pertoire.\n",
    "    \n",
    "    Returns:\n",
    "        features: np.array de shape (n_samples, feature_dim)\n",
    "        labels: np.array de shape (n_samples,)\n",
    "        paths: liste des chemins d'images\n",
    "    \"\"\"\n",
    "    features_list = []\n",
    "    labels_list = []\n",
    "    paths_list = []\n",
    "    \n",
    "    extractor.eval()\n",
    "    \n",
    "    # TODO: Parcourir les images et extraire les features\n",
    "    # Hint: \n",
    "    # 1. Charger l'image avec PIL\n",
    "    # 2. Appliquer transform\n",
    "    # 3. Passer dans extractor\n",
    "    # 4. Ajouter aux listes\n",
    "    \n",
    "    # VOTRE CODE ICI\n",
    "    \n",
    "    return np.array(features_list), np.array(labels_list), paths_list\n",
    "\n",
    "# Extraction\n",
    "# X_train, y_train, paths_train = extract_all_features(TRAIN_DIR, extractor, test_transform)\n",
    "# print(f\"Features train: {X_train.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# üß† SECTION 3b: Entra√Ænement CNN Baseline (Deep Learning)\n",
    "---\n",
    "\n",
    "## üí° Objectif\n",
    "Entra√Æner un CNN from scratch pour comparer avec l'approche hybride (features pr√©-entra√Æn√©es + shallow classifiers).\n",
    "\n",
    "### Architecture sugg√©r√©e:\n",
    "```\n",
    "Input (224√ó224√ó3)\n",
    "    ‚Üì\n",
    "Conv2D(32) ‚Üí BatchNorm ‚Üí ReLU ‚Üí MaxPool\n",
    "    ‚Üì\n",
    "Conv2D(64) ‚Üí BatchNorm ‚Üí ReLU ‚Üí MaxPool\n",
    "    ‚Üì\n",
    "Conv2D(128) ‚Üí BatchNorm ‚Üí ReLU ‚Üí MaxPool\n",
    "    ‚Üì\n",
    "Conv2D(256) ‚Üí BatchNorm ‚Üí ReLU ‚Üí MaxPool\n",
    "    ‚Üì\n",
    "Global Average Pooling\n",
    "    ‚Üì\n",
    "FC(256) ‚Üí ReLU ‚Üí Dropout\n",
    "    ‚Üì\n",
    "FC(2) ‚Üí Softmax\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: D√©finir le CNN Baseline\n",
    "class BaselineCNN(nn.Module):\n",
    "    \"\"\"\n",
    "    CNN personnalis√© pour la classification de d√©fauts.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, num_classes=2):\n",
    "        super().__init__()\n",
    "        \n",
    "        # TODO: D√©finir les couches convolutionnelles\n",
    "        # Hint: nn.Conv2d(in_channels, out_channels, kernel_size)\n",
    "        # Hint: nn.BatchNorm2d(num_features)\n",
    "        # Hint: nn.MaxPool2d(kernel_size)\n",
    "        \n",
    "        self.features = nn.Sequential(\n",
    "            # Block 1: 3 ‚Üí 32\n",
    "            # VOTRE CODE ICI\n",
    "            \n",
    "            # Block 2: 32 ‚Üí 64\n",
    "            # VOTRE CODE ICI\n",
    "            \n",
    "            # Block 3: 64 ‚Üí 128\n",
    "            # VOTRE CODE ICI\n",
    "            \n",
    "            # Block 4: 128 ‚Üí 256\n",
    "            # VOTRE CODE ICI\n",
    "        )\n",
    "        \n",
    "        # Global Average Pooling\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        \n",
    "        # Classifier\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(256, 256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(256, num_classes)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.avgpool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "# Test\n",
    "# model = BaselineCNN().to(DEVICE)\n",
    "# dummy = torch.randn(1, 3, 224, 224).to(DEVICE)\n",
    "# output = model(dummy)\n",
    "# print(f\"Output shape: {output.shape}\")  # Devrait √™tre (1, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Fonction d'entra√Ænement du CNN\n",
    "def train_cnn(model, train_loader, val_loader, epochs=20, lr=0.001):\n",
    "    \"\"\"\n",
    "    Entra√Æne le CNN avec early stopping.\n",
    "    \n",
    "    Args:\n",
    "        model: Le CNN √† entra√Æner\n",
    "        train_loader: DataLoader d'entra√Ænement\n",
    "        val_loader: DataLoader de validation\n",
    "        epochs: Nombre d'√©poques maximum\n",
    "        lr: Learning rate\n",
    "    \n",
    "    Returns:\n",
    "        model: Le mod√®le entra√Æn√©\n",
    "        history: Dict avec les m√©triques par √©poque\n",
    "    \"\"\"\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "        optimizer, mode='min', factor=0.5, patience=3\n",
    "    )\n",
    "    \n",
    "    history = {'train_loss': [], 'val_loss': [], 'val_acc': []}\n",
    "    best_val_loss = float('inf')\n",
    "    patience_counter = 0\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        # TODO: Impl√©menter la boucle d'entra√Ænement\n",
    "        # 1. model.train()\n",
    "        # 2. Pour chaque batch: forward ‚Üí loss ‚Üí backward ‚Üí step\n",
    "        # 3. model.eval() pour validation\n",
    "        # 4. Calculer val_loss et val_acc\n",
    "        # 5. Early stopping si pas d'am√©lioration\n",
    "        \n",
    "        # VOTRE CODE ICI\n",
    "        \n",
    "        print(f\"Epoch {epoch+1}/{epochs}\")\n",
    "    \n",
    "    return model, history\n",
    "\n",
    "# Entra√Ænement\n",
    "# cnn_model = BaselineCNN().to(DEVICE)\n",
    "# cnn_model, history = train_cnn(cnn_model, train_loader, val_loader, epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Visualiser les courbes d'apprentissage\n",
    "def plot_training_history(history):\n",
    "    \"\"\"\n",
    "    Affiche les courbes de loss et accuracy.\n",
    "    \"\"\"\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))\n",
    "    \n",
    "    # Loss\n",
    "    ax1.plot(history['train_loss'], label='Train Loss')\n",
    "    ax1.plot(history['val_loss'], label='Val Loss')\n",
    "    ax1.set_xlabel('Epoch')\n",
    "    ax1.set_ylabel('Loss')\n",
    "    ax1.legend()\n",
    "    ax1.set_title('Training & Validation Loss')\n",
    "    \n",
    "    # Accuracy\n",
    "    ax2.plot(history['val_acc'], label='Val Accuracy', color='green')\n",
    "    ax2.set_xlabel('Epoch')\n",
    "    ax2.set_ylabel('Accuracy')\n",
    "    ax2.legend()\n",
    "    ax2.set_title('Validation Accuracy')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# plot_training_history(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üí° Optimisation du CNN (si n√©cessaire)\n",
    "\n",
    "Si les performances ne sont pas satisfaisantes:\n",
    "1. **Data Augmentation** plus agressive\n",
    "2. **Learning Rate Scheduler** (ReduceLROnPlateau)\n",
    "3. **Regularization** (Dropout, Weight Decay)\n",
    "4. **Architecture** (plus de couches, plus de filtres)\n",
    "5. **Transfer Learning** (fine-tuning d'un mod√®le pr√©-entra√Æn√©)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Fine-tuning d'un mod√®le pr√©-entra√Æn√© (alternative au CNN from scratch)\n",
    "def create_finetuned_model(model_name='resnet50', num_classes=2, freeze_ratio=0.8):\n",
    "    \"\"\"\n",
    "    Cr√©e un mod√®le pr√©-entra√Æn√© pour fine-tuning.\n",
    "    \n",
    "    Args:\n",
    "        model_name: 'resnet50', 'vgg16', etc.\n",
    "        num_classes: Nombre de classes (2 pour notre cas)\n",
    "        freeze_ratio: Proportion des couches √† geler (0.8 = 80% gel√©es)\n",
    "    \"\"\"\n",
    "    if model_name == 'resnet50':\n",
    "        model = models.resnet50(pretrained=True)\n",
    "        # Remplacer la derni√®re couche\n",
    "        model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
    "        \n",
    "        # Geler les premi√®res couches\n",
    "        layers = list(model.children())\n",
    "        freeze_until = int(len(layers) * freeze_ratio)\n",
    "        for i, layer in enumerate(layers[:freeze_until]):\n",
    "            for param in layer.parameters():\n",
    "                param.requires_grad = False\n",
    "    \n",
    "    # TODO: Ajouter VGG16, DenseNet si besoin\n",
    "    \n",
    "    return model\n",
    "\n",
    "# model_ft = create_finetuned_model('resnet50').to(DEVICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# üìä SECTION 3c: Comparaison CNN vs Shallow Methods\n",
    "---\n",
    "\n",
    "## üéØ Objectif\n",
    "Comparer les performances de:\n",
    "1. **CNN Baseline** (entra√Æn√© from scratch)\n",
    "2. **CNN Fine-tun√©** (transfer learning)\n",
    "3. **Features pr√©-entra√Æn√©es + Shallow Classifiers**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Cr√©er un tableau de comparaison\n",
    "def compare_models(models_results):\n",
    "    \"\"\"\n",
    "    Compare les performances de plusieurs mod√®les.\n",
    "    \n",
    "    Args:\n",
    "        models_results: Dict {'model_name': {'accuracy': ..., 'recall': ..., 'f1': ...}}\n",
    "    \n",
    "    Returns:\n",
    "        DataFrame avec la comparaison\n",
    "    \"\"\"\n",
    "    df = pd.DataFrame(models_results).T\n",
    "    df = df.sort_values('f1', ascending=False)\n",
    "    \n",
    "    # Afficher avec style\n",
    "    styled = df.style.background_gradient(cmap='Greens', subset=['accuracy', 'recall', 'f1'])\n",
    "    \n",
    "    return styled\n",
    "\n",
    "# Exemple d'utilisation:\n",
    "# results = {\n",
    "#     'CNN Baseline': {'accuracy': 0.85, 'precision': 0.83, 'recall': 0.80, 'f1': 0.82},\n",
    "#     'ResNet50 + SVM': {'accuracy': 0.90, 'precision': 0.89, 'recall': 0.88, 'f1': 0.89},\n",
    "#     'ResNet50 + XGBoost': {'accuracy': 0.92, 'precision': 0.91, 'recall': 0.90, 'f1': 0.91},\n",
    "#     'VGG16 + RandomForest': {'accuracy': 0.88, 'precision': 0.86, 'recall': 0.85, 'f1': 0.86},\n",
    "# }\n",
    "# compare_models(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisation graphique de la comparaison\n",
    "def plot_model_comparison(results):\n",
    "    \"\"\"\n",
    "    Graphique de comparaison des mod√®les.\n",
    "    \"\"\"\n",
    "    df = pd.DataFrame(results).T.reset_index()\n",
    "    df = df.rename(columns={'index': 'Model'})\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    \n",
    "    x = np.arange(len(df))\n",
    "    width = 0.2\n",
    "    \n",
    "    ax.bar(x - width, df['accuracy'], width, label='Accuracy', color='#2E86AB')\n",
    "    ax.bar(x, df['recall'], width, label='Recall', color='#F18F01')\n",
    "    ax.bar(x + width, df['f1'], width, label='F1-Score', color='#4CAF50')\n",
    "    \n",
    "    ax.set_ylabel('Score')\n",
    "    ax.set_title('Comparaison des Mod√®les')\n",
    "    ax.set_xticks(x)\n",
    "    ax.set_xticklabels(df['Model'], rotation=45, ha='right')\n",
    "    ax.legend()\n",
    "    ax.set_ylim(0, 1)\n",
    "    ax.axhline(y=0.9, color='red', linestyle='--', alpha=0.5, label='Objectif 90%')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# plot_model_comparison(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# üó≥Ô∏è SECTION 3d: Ensemble - Vote Majoritaire\n",
    "---\n",
    "\n",
    "## üí° Concept\n",
    "\n",
    "Combiner les pr√©dictions de plusieurs mod√®les:\n",
    "- Si la majorit√© pr√©dit \"D√©faut\" ‚Üí Pr√©diction finale = \"D√©faut\"\n",
    "- Confiance = nombre de votes pour la classe gagnante / total des mod√®les\n",
    "\n",
    "### Avantages:\n",
    "- Plus robuste qu'un seul mod√®le\n",
    "- R√©duit le risque de faux n√©gatifs\n",
    "- Capture diff√©rentes \"perspectives\" sur les donn√©es"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EnsemblePredictor:\n",
    "    \"\"\"\n",
    "    Pr√©dicteur ensemble avec vote majoritaire.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.models = {}  # {'model_name': (model, feature_extractor, scaler)}\n",
    "        self.cnn_models = {}  # CNN models qui pr√©disent directement\n",
    "    \n",
    "    def add_shallow_model(self, name, model, feature_extractor, scaler):\n",
    "        \"\"\"\n",
    "        Ajoute un mod√®le shallow (SVM, XGBoost, etc.)\n",
    "        \"\"\"\n",
    "        self.models[name] = {\n",
    "            'model': model,\n",
    "            'extractor': feature_extractor,\n",
    "            'scaler': scaler\n",
    "        }\n",
    "    \n",
    "    def add_cnn_model(self, name, model):\n",
    "        \"\"\"\n",
    "        Ajoute un mod√®le CNN (pr√©dit directement sur l'image)\n",
    "        \"\"\"\n",
    "        self.cnn_models[name] = model\n",
    "    \n",
    "    def predict(self, image_tensor):\n",
    "        \"\"\"\n",
    "        Pr√©dit avec vote majoritaire.\n",
    "        \n",
    "        Args:\n",
    "            image_tensor: Tensor de l'image (1, 3, 224, 224)\n",
    "        \n",
    "        Returns:\n",
    "            dict: {\n",
    "                'prediction': 0 ou 1,\n",
    "                'confidence': float,\n",
    "                'votes': {'defective': n, 'non_defective': m},\n",
    "                'model_predictions': {'model_name': pred, ...}\n",
    "            }\n",
    "        \"\"\"\n",
    "        predictions = {}\n",
    "        \n",
    "        # TODO: Pr√©dictions des CNN\n",
    "        for name, model in self.cnn_models.items():\n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "                output = model(image_tensor.to(DEVICE))\n",
    "                pred = output.argmax(dim=1).item()\n",
    "                predictions[name] = pred\n",
    "        \n",
    "        # TODO: Pr√©dictions des shallow models\n",
    "        for name, components in self.models.items():\n",
    "            extractor = components['extractor']\n",
    "            scaler = components['scaler']\n",
    "            model = components['model']\n",
    "            \n",
    "            # Extraire features\n",
    "            extractor.eval()\n",
    "            with torch.no_grad():\n",
    "                features = extractor(image_tensor.to(DEVICE))\n",
    "                features = features.cpu().numpy().flatten().reshape(1, -1)\n",
    "            \n",
    "            # Normaliser\n",
    "            features_scaled = scaler.transform(features)\n",
    "            \n",
    "            # Pr√©dire\n",
    "            pred = model.predict(features_scaled)[0]\n",
    "            predictions[name] = pred\n",
    "        \n",
    "        # Vote majoritaire\n",
    "        votes = list(predictions.values())\n",
    "        defective_votes = sum(votes)\n",
    "        non_defective_votes = len(votes) - defective_votes\n",
    "        \n",
    "        final_pred = 1 if defective_votes > non_defective_votes else 0\n",
    "        confidence = max(defective_votes, non_defective_votes) / len(votes)\n",
    "        \n",
    "        return {\n",
    "            'prediction': final_pred,\n",
    "            'class_name': 'Defective' if final_pred == 1 else 'Non-Defective',\n",
    "            'confidence': confidence,\n",
    "            'votes': {\n",
    "                'defective': defective_votes,\n",
    "                'non_defective': non_defective_votes\n",
    "            },\n",
    "            'model_predictions': predictions\n",
    "        }\n",
    "\n",
    "# Exemple d'utilisation:\n",
    "# ensemble = EnsemblePredictor()\n",
    "# ensemble.add_cnn_model('CNN_Baseline', cnn_model)\n",
    "# ensemble.add_shallow_model('ResNet50_SVM', svm_model, resnet_extractor, scaler)\n",
    "# result = ensemble.predict(image_tensor)\n",
    "# print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# üéØ SECTION 4: Entra√Ænement des Classifiers\n",
    "---\n",
    "\n",
    "## üí° Approche Hybride\n",
    "Deep Features (CNN) + Shallow Classifiers (ML)\n",
    "\n",
    "### Classifiers √† tester:\n",
    "1. **SVM** - Support Vector Machine\n",
    "2. **Random Forest** - Ensemble d'arbres\n",
    "3. **XGBoost** - Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalisation des features (IMPORTANT!)\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# TODO: Normaliser vos features\n",
    "# X_train_scaled = scaler.fit_transform(X_train)\n",
    "# X_test_scaled = scaler.transform(X_test)  # Utiliser le m√™me scaler!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Entra√Æner un SVM\n",
    "def train_svm(X_train, y_train):\n",
    "    \"\"\"\n",
    "    Entra√Æne un SVM avec kernel RBF.\n",
    "    \n",
    "    Hint: sklearn.svm.SVC\n",
    "    Param√®tres importants: C, kernel, gamma\n",
    "    \"\"\"\n",
    "    # VOTRE CODE ICI\n",
    "    model = None\n",
    "    return model\n",
    "\n",
    "# TODO: Entra√Æner un Random Forest\n",
    "def train_random_forest(X_train, y_train):\n",
    "    \"\"\"\n",
    "    Entra√Æne un Random Forest.\n",
    "    \n",
    "    Param√®tres importants: n_estimators, max_depth\n",
    "    \"\"\"\n",
    "    # VOTRE CODE ICI\n",
    "    model = None\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# üìè SECTION 5: √âvaluation du Mod√®le\n",
    "---\n",
    "\n",
    "## üí° M√©triques importantes\n",
    "\n",
    "Dans le contexte industriel:\n",
    "- **Recall** est CRITIQUE (ne pas manquer de d√©fauts)\n",
    "- **F1-Score** pour la balance globale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, X_test, y_test):\n",
    "    \"\"\"\n",
    "    √âvalue un mod√®le et affiche les m√©triques.\n",
    "    \"\"\"\n",
    "    # Pr√©dictions\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # M√©triques\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    \n",
    "    print(\"=\" * 50)\n",
    "    print(\"R√âSULTATS D'√âVALUATION\")\n",
    "    print(\"=\" * 50)\n",
    "    print(f\"Accuracy:  {accuracy:.4f}\")\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Recall:    {recall:.4f}  ‚¨ÖÔ∏è IMPORTANT!\")\n",
    "    print(f\"F1-Score:  {f1:.4f}\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # Matrice de confusion\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "                xticklabels=['Non-D√©faut', 'D√©faut'],\n",
    "                yticklabels=['Non-D√©faut', 'D√©faut'])\n",
    "    plt.xlabel('Pr√©dit')\n",
    "    plt.ylabel('R√©el')\n",
    "    plt.title('Matrice de Confusion')\n",
    "    plt.show()\n",
    "    \n",
    "    return {'accuracy': accuracy, 'precision': precision, 'recall': recall, 'f1': f1}\n",
    "\n",
    "# Usage:\n",
    "# results = evaluate_model(svm_model, X_test_scaled, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# ‚öôÔ∏è SECTION 6: Optimisation des Hyperparam√®tres (Jour 2)\n",
    "---\n",
    "\n",
    "## üí° Grid Search\n",
    "Recherche exhaustive des meilleurs hyperparam√®tres."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grid Search pour SVM, RandomForest, XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Grid Search pour SVM\n",
    "def optimize_svm(X_train, y_train):\n",
    "    \"\"\"\n",
    "    Trouve les meilleurs hyperparam√®tres pour SVM.\n",
    "    \n",
    "    Hint: GridSearchCV avec cv=5 (5-fold cross-validation)\n",
    "    \"\"\"\n",
    "    param_grid = {\n",
    "        'C': [0.1, 1, 10, 100],\n",
    "        'kernel': ['rbf', 'linear'],\n",
    "        'gamma': ['scale', 'auto']\n",
    "    }\n",
    "    \n",
    "    # VOTRE CODE ICI\n",
    "    # Hint: GridSearchCV(SVC(), param_grid, cv=5, scoring='f1')\n",
    "    \n",
    "    best_model = None\n",
    "    best_params = None\n",
    "    \n",
    "    return best_model, best_params\n",
    "\n",
    "# best_svm, best_params = optimize_svm(X_train_scaled, y_train)\n",
    "# print(f\"Meilleurs param√®tres: {best_params}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# üåê Interface Streamlit (Jour 2-4)\n",
    "---\n",
    "\n",
    "## üí° Structure de l'application\n",
    "\n",
    "```python\n",
    "# app.py\n",
    "import streamlit as st\n",
    "from PIL import Image\n",
    "\n",
    "st.title(\"üîç D√©tection de D√©fauts\")\n",
    "\n",
    "# Upload\n",
    "uploaded = st.file_uploader(\"Upload image\", type=['jpg', 'png'])\n",
    "\n",
    "if uploaded:\n",
    "    image = Image.open(uploaded)\n",
    "    st.image(image, caption=\"Image upload√©e\")\n",
    "    \n",
    "    if st.button(\"Analyser\"):\n",
    "        # 1. Pr√©diction\n",
    "        prediction, confidence = model.predict(image)\n",
    "        \n",
    "        # 2. Afficher r√©sultat\n",
    "        if prediction == 1:\n",
    "            st.error(f\"‚ö†Ô∏è D√âFAUT D√âTECT√â - Confiance: {confidence:.1%}\")\n",
    "        else:\n",
    "            st.success(f\"‚úÖ OK - Confiance: {confidence:.1%}\")\n",
    "        \n",
    "        \n",
    "```\n",
    "\n",
    "### Lancer l'application:\n",
    "```bash\n",
    "streamlit run app.py\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# üíæ Sauvegarde des Mod√®les\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import pickle\n",
    "\n",
    "def save_pipeline(models_dir, classifier, scaler, cbir_data):\n",
    "    \"\"\"\n",
    "    Sauvegarde tous les composants n√©cessaires.\n",
    "    \"\"\"\n",
    "    models_dir = Path(models_dir)\n",
    "    models_dir.mkdir(exist_ok=True)\n",
    "    \n",
    "    # Classifier\n",
    "    joblib.dump(classifier, models_dir / 'classifier.pkl')\n",
    "    \n",
    "    # Scaler\n",
    "    joblib.dump(scaler, models_dir / 'scaler.pkl')\n",
    "    \n",
    "    # CBIR data\n",
    "    with open(models_dir / 'cbir_signatures.pkl', 'wb') as f:\n",
    "        pickle.dump(cbir_data, f)\n",
    "    \n",
    "    print(f\"‚úÖ Mod√®les sauvegard√©s dans {models_dir}\")\n",
    "\n",
    "# Usage:\n",
    "# save_pipeline(\n",
    "#     MODELS_DIR,\n",
    "#     classifier=best_svm,\n",
    "#     scaler=scaler,\n",
    "#     cbir_data={'features': X_train, 'labels': y_train, 'paths': paths_train}\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# ‚úÖ CHECKLIST FINALE\n",
    "---\n",
    "\n",
    "## Jour 1\n",
    "- [ ] EDA compl√®te\n",
    "- [ ] Dataset et DataLoader fonctionnels\n",
    "- [ ] Feature extraction avec CNN\n",
    "- [ ] Baseline classifier entra√Æn√©\n",
    "- [ ] M√©triques √©valu√©es\n",
    "\n",
    "## Jour 2\n",
    "- [ ] Grid Search impl√©ment√©\n",
    "- [ ] Meilleurs hyperparam√®tres trouv√©s\n",
    "- [ ] Interface Streamlit de base\n",
    "\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
